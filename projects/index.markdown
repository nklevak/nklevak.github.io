---
layout: page
title: Projects :)
permalink: /projects/
---

### Ongoing Projects
<details>
  <summary><span class="arrow">&#9654;</span> <em style="font-size:0.9em;">How does fatigue relate to effort? And how does task switching influence this?</em></summary>
  <p style="font-size:0.85em;">The overarching goal of this project is to understand how cognitive fatigue relates to effort, and how switching between tasks may alter that relationship. So far, I have designed an online behavioral task to analyze how self-selected rest times change depending on performance levels and task switches. Currently, I am developing a computational model based on this data to better understand the impact of task switches on the rejuvenating aspects of rest.</p>
</details>
<details>
  <summary><span class="arrow">&#9654;</span> <em style="font-size:0.9em;">How are learning effects reflected in the brain?</em></summary>
  <p style="font-size:0.85em;">This project aims to understand changes in brain activity when people get more experience with a specific task. Currently, I am using an fMRI dataset where subjects had numerous experiences with the same cognitive control tasks to understand how the distribution of activated networks changes over time from practice.</p>
</details>


<br>
### Previous work
<details>
  <summary><span class="arrow">&#9654;</span> <em style="font-size:0.9em;">Simulating language conventions in emerging sign language communities</em></summary>
  <p style="font-size:0.85em;">Advised by Tom Griffiths as well as Bill Thompson and Robert Hawkins, this project was the result of a semester-long independent work research project at Princeton. We utilized, coded, and adapted multiple versions of a Hierarchical Bayesian Model to simulate language emergence in various population sizes. By testing models that accounted for partner-specific memory, this project then identified which model best matched with qualitative data about how emerging sign languages develop.</p>
</details>
<details>
  <summary><span class="arrow">&#9654;</span> <em style="font-size:0.9em;">The efficacy of CLIP’s object recognition on photos taken by the Visually Impaired</em></summary>
  <p style="font-size:0.85em;">Advised by Olga Russakovsky at Princeton, this project was the result of a semester-long independent work research project during my undergraduate degree. I tested the CLIP image recognition system on a dataset of images taken by the Blind or Visually Impaired (the VizWiz-Captions dataset), to identify whether this novel image recognition system—not explicitly trained on images from sighted individuals—would be able to fulfill the needs of a large part of the population. In doing so, I developed a system to statistically evaluate CLIP’s accuracy on this dataset, and attempted to improve it’s accuracy by fine-tuning a neural network classifier and adding it to the testing pipeline.</p>
</details>