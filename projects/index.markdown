---
layout: page
title: Projects :)
permalink: /projects/
---

### Ongoing Projects
<details>
  <summary><span style="font-size:0.7em;"></span> <em>How does fatigue relate to effort? And how does task switching influence this?</em></summary>
  <p>The overarching goal of this project is to understand how cognitive fatigue relates to effort, and how switching between tasks may alter that relationship. So far, I have designed an online behavioral task to analyze how self-selected rest times change depending on performance levels and task switches. Currently, I am developing a computational model based on this data to better understand the impact of task switches on the rejuvenating aspects of rest.</p>
</details>
<br>
<details>
  <summary><span style="font-size:0.7em;"></span> <em>How are learning effects reflected in the brain?</em></summary>
  <p>This project aims to understand changes in brain activity when people get more experience with a specific task. Currently, I am using an fMRI dataset where subjects had numerous experiences with the same cognitive control tasks to understand how the distribution of activated networks changes over time from practice.</p>
</details>



### Previous work
<details>
  <summary><span style="font-size:0.7em;"></span> <em>Understanding and Simulating Language Conventions in Emerging Sign Language Communities</em></summary>
  <p>Advised by Tom Griffiths as well as Bill Thompson and Robert Hawkins, this project was the result of a semester-long independent work research project at Princeton. We utilized, coded, and adapted multiple versions of a Hierarchical Bayesian Model to simulate language emergence in various population sizes. By testing models that accounted for partner-specific memory, this project then identified which model best matched with qualitative data about how emerging sign languages develop.</p>
</details>
<br>
<details>
  <summary><span style="font-size:0.8em;"></span> <em>Investigating the Efficacy of CLIP’s Object Recognition on Photos Taken by the Visually Impaired</em></summary>
  <p>Advised by Olga Russakovsky at Princeton, this project was the result of a semester-long independent work research project during my undergraduate degree. I tested the CLIP image recognition system on a dataset of images taken by the Blind or Visually Impaired (the VizWiz-Captions dataset), to identify whether this novel image recognition system—not explicitly trained on images from sighted individuals—would be able to fulfill the needs of a large part of the population. In doing so, I developed a system to statistically evaluate CLIP’s accuracy on this dataset, and attempted to improve it’s accuracy by fine-tuning a neural network classifier and adding it to the testing pipeline.</p>
</details>